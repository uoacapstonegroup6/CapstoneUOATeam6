{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uoacapstonegroup6/CapstoneUOATeam6/blob/main/CapstoneProject_MedVit_FractureMNIST3d_FinalCopy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H8U1fAPk9sx",
        "outputId": "2af01e77-4cbc-4135-9eac-fbaff07e2c92",
        "collapsed": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: medmnist in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.0.1)\n",
            "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (1.26.4)\n",
            "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (1.3.2)\n",
            "Requirement already satisfied: scikit-image in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (0.24.0)\n",
            "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (4.66.5)\n",
            "Requirement already satisfied: Pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (10.4.0)\n",
            "Requirement already satisfied: fire in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (0.6.0)\n",
            "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from medmnist) (0.17.1+cu121)\n",
            "Requirement already satisfied: six in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fire->medmnist) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->medmnist) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->medmnist) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->medmnist) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->medmnist) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->medmnist) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->medmnist) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->medmnist) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->medmnist) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->medmnist) (3.5.0)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (4.12.2)\n",
            "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (1.13.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->medmnist) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->medmnist) (12.6.68)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch->medmnist) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch->medmnist) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Install the MedMNIST library, a large-scale benchmark dataset for medical image classification tasks\n",
        "\n",
        "!pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSHT-tRHTA7w",
        "outputId": "71057304-e07e-41d6-fd91-e7c595a63cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/exouser/Documents/RRR_MedVit\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/exouser/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "%cd '/home/exouser/Documents/RRR_MedVit'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9uHe4stROGP",
        "outputId": "7c274ee4-80a1-4278-ea94-c0d1c113fea9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/exouser/Documents/RRR_MedVit'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugv-2jKMROGP"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbbvyQ70ROGQ",
        "outputId": "af55d0cb-ecbf-4b17-d213-220898a7962a"
      },
      "source": [
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNuU3tj7ROGQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGeJbS3zROGQ"
      },
      "source": [
        "# Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4S62dEcROGQ"
      },
      "outputs": [],
      "source": [
        "# data_flag = 'vesselmnist3d'\n",
        "# data_flag='synapsemnist3d'\n",
        "data_flag = 'fracturemnist3d'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orGI_UCsROGQ",
        "outputId": "ef2d9af0-91e7-4dee-8c27-95941e32790b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /home/exouser/.medmnist/fracturemnist3d_64.npz\n",
            "Using downloaded and verified file: /home/exouser/.medmnist/fracturemnist3d_64.npz\n",
            "Using downloaded and verified file: /home/exouser/.medmnist/fracturemnist3d_64.npz\n"
          ]
        }
      ],
      "source": [
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "train_dataset = DataClass(split='train', download=True,size=64)\n",
        "val_dataset = DataClass(split='val', download=True,size=64)\n",
        "test_dataset = DataClass(split='test', download=True,size=64)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz7lAOvNROGQ"
      },
      "outputs": [],
      "source": [
        "# Create directories for saving 2D frames\n",
        "train_dir = f'./{data_flag}/train'\n",
        "valid_dir = f'./{data_flag}/valid'\n",
        "test_dir = f'./{data_flag}/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mTTwEeMGROGR"
      },
      "outputs": [],
      "source": [
        "\n",
        "for dir in [train_dir, valid_dir, test_dir]:\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "# Extract 2D slices from 3D data and save to local drive\n",
        "def extract_and_save_2d_slices(dataset, dir):\n",
        "    for idx, img in enumerate(dataset.imgs):\n",
        "        label = dataset.labels[idx]\n",
        "        for i in range(img.shape[0]):  # Extract each of the 64 frames\n",
        "            slice_2d = img[i, :, :]\n",
        "            slice_2d_img = Image.fromarray(slice_2d)\n",
        "            filename = f\"{idx}_{i}.png\"\n",
        "            filepath = os.path.join(dir, str(label), filename)\n",
        "            if not os.path.exists(os.path.dirname(filepath)):\n",
        "                os.makedirs(os.path.dirname(filepath))\n",
        "            slice_2d_img.save(filepath)\n",
        "\n",
        "extract_and_save_2d_slices(train_dataset, train_dir)\n",
        "extract_and_save_2d_slices(val_dataset, valid_dir)\n",
        "extract_and_save_2d_slices(test_dataset, test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O2xm1_KROGR"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1pwjElNROGR",
        "outputId": "d9265a9c-01be-4838-d699-e6c3a461fd3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset FractureMNIST3D of size 64 (fracturemnist3d_64)\n",
            "    Number of datapoints: 240\n",
            "    Root location: /home/exouser/.medmnist\n",
            "    Split: test\n",
            "    Task: multi-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'buckle rib fracture', '1': 'nondisplaced rib fracture', '2': 'displaced rib fracture'}\n",
            "    Number of samples: {'train': 1027, 'val': 103, 'test': 240}\n",
            "    Description: The FractureMNIST3D is based on the RibFrac Dataset, containing around 5,000 rib fractures from 660 computed tomography 153 (CT) scans. The dataset organizes detected rib fractures into 4 clinical categories (i.e., buckle, nondisplaced, displaced, and segmental rib fractures). As we use low-resolution images, we disregard segmental rib fractures and classify 3 types of rib fractures (i.e., buckle, nondisplaced, and displaced). For each annotated fracture area, we calculate its center and resize the center-cropped 64mm×64mm×64mm image into 28×28×28. The official split of training, validation and test set is used.\n",
            "    License: CC BY 4.0\n"
          ]
        }
      ],
      "source": [
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ0pY79AROGR",
        "outputId": "e084a69b-e3c5-4d00-d0bd-9cd73466341c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 64, 64, 64) (1,)\n"
          ]
        }
      ],
      "source": [
        "x, y = test_dataset[0]\n",
        "\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J94eWLnSROGR",
        "outputId": "2e14659a-a2a8-4d41-9325-d752b3ffec0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "print(x[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nb_J-BJuROGR",
        "outputId": "b339f278-931f-4384-8756-324c942bf052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['[0]', '[2]', '[1]']"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(test_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EA-tSdhROGR"
      },
      "outputs": [],
      "source": [
        "label_dir = os.path.join(test_dir, '[0]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9AEA_ejROGR",
        "outputId": "ae852254-7ac2-42ee-dcf8-7a0f6ed26198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./fracturemnist3d/test/[0]\n"
          ]
        }
      ],
      "source": [
        "print(label_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the directory containing the images\n",
        "label_dir = os.path.join(test_dir, '[1]')\n",
        "\n",
        "# Select the base name of the image you want to display, e.g., '1000'\n",
        "base_image = '100'\n",
        "\n",
        "# Create a list to store the image slices and filenames\n",
        "image_slices = []\n",
        "image_names = []\n",
        "\n",
        "# Load the slices from 0 to 63\n",
        "for i in range(64):\n",
        "    # Construct the image file name\n",
        "    img_name = f\"{base_image}_{i}.png\"\n",
        "    img_path = os.path.join(label_dir, img_name)\n",
        "\n",
        "    # Load the image and append it to the list\n",
        "    if os.path.exists(img_path):\n",
        "        image_slices.append(Image.open(img_path))\n",
        "        image_names.append(img_name)\n",
        "    else:\n",
        "        print(f\"Image {img_name} not found\")\n",
        "\n",
        "# Plot the slices\n",
        "fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    if i < len(image_slices):\n",
        "        ax.imshow(image_slices[i], cmap='gray')\n",
        "        ax.set_title(image_names[i], fontsize=8)  # Display filename below each image\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5NCNl2VqZK-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXFbroYFROGS"
      },
      "outputs": [],
      "source": [
        "# Create a custom dataset class to handle 2D slices\n",
        "class SliceDataset(data.Dataset):\n",
        "    def __init__(self, dir, transform=None):\n",
        "        self.dir = dir\n",
        "        self.transform = transform\n",
        "        self.labels = []\n",
        "        self.filenames = []\n",
        "        self.image_ids = []\n",
        "        for label in os.listdir(dir):\n",
        "            label_value = int(label.strip('[]'))\n",
        "            label_dir = os.path.join(dir, label)\n",
        "            for filename in os.listdir(label_dir):\n",
        "                image_id = filename.split('_')[0]  # Extract 3D image ID (e.g., '12' from '12_0.png')\n",
        "                self.labels.append(label_value)\n",
        "                self.filenames.append(os.path.join(label_dir, filename))\n",
        "                self.image_ids.append(image_id)  # Store the image ID for tracking\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.filenames[idx]\n",
        "        img = Image.open(filename)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.labels[idx], self.image_ids[idx]\n",
        "\n",
        "# # Create data loaders for the 2D slices\n",
        "# data_transform = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[.5], std=[.5])\n",
        "# ])\n",
        "# preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    #torchvision.transforms.AugMix(),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "train_slice_dataset = SliceDataset(train_dir, transform=train_transform)\n",
        "valid_slice_dataset = SliceDataset(valid_dir, transform=test_transform)\n",
        "test_slice_dataset = SliceDataset(test_dir, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1KTdhdcTA70"
      },
      "outputs": [],
      "source": [
        "# Custom DataLoader to ensure batches of 64 slices from the same 3D image\n",
        "def collate_fn(batch):\n",
        "    batch_images = []\n",
        "    batch_labels = []\n",
        "    current_image_id = batch[0][2]  # Get the 3D image ID of the first element in the batch\n",
        "\n",
        "    # Print the 3D image ID being processed\n",
        "    print(f\"Processing 3D image ID: {current_image_id}\")\n",
        "\n",
        "    for img, label, image_id in batch:\n",
        "        if image_id != current_image_id:\n",
        "            raise ValueError(f\"Mixed slices in batch. Expected image ID {current_image_id}, but got {image_id}\")\n",
        "        batch_images.append(img)\n",
        "        batch_labels.append(label)\n",
        "\n",
        "    return torch.stack(batch_images), torch.tensor(batch_labels) # Stack the images as tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eozJ2wuIROGS"
      },
      "outputs": [],
      "source": [
        "lr = 0.001\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10\n",
        "train_loader = data.DataLoader(dataset=train_slice_dataset, batch_size=BATCH_SIZE, shuffle=True, )\n",
        "valid_loader = data.DataLoader(dataset=valid_slice_dataset, batch_size=BATCH_SIZE, shuffle=True, )\n",
        "test_loader = data.DataLoader(dataset=test_slice_dataset, batch_size=BATCH_SIZE, shuffle=False,  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrbUYYjnTA70",
        "outputId": "18b19944-6464-4662-cc35-3d5362683bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size: torch.Size([64, 3, 224, 224]), Labels: tensor([0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 2, 1, 2, 1, 0, 0, 1, 1, 0, 0, 0, 0, 2, 0,\n",
            "        2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 2, 0, 1, 2, 0, 0, 2, 1, 0, 1, 0,\n",
            "        1, 0, 2, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 2, 1]), Slice numbers: ('44', '209', '246', '219', '990', '127', '273', '747', '781', '154', '939', '1001', '312', '775', '318', '566', '983', '990', '807', '51', '390', '893', '310', '124', '543', '740', '959', '962', '267', '132', '206', '377', '268', '382', '46', '822', '846', '871', '807', '144', '167', '645', '814', '556', '183', '700', '876', '999', '817', '489', '506', '244', '79', '880', '217', '228', '777', '327', '934', '204', '541', '382', '400', '646')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Check the data loader by fetching one batch\n",
        "data_iter = iter(train_loader)\n",
        "images, labels, slice_numbers = next(data_iter)\n",
        "print(f\"Batch size: {images.size()}, Labels: {labels}, Slice numbers: {slice_numbers}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MedVit Training"
      ],
      "metadata": {
        "id": "HoF4ySBCLyTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MedVit\n",
        "!git clone https://github.com/Omid-Nejati/MedViT.git"
      ],
      "metadata": {
        "id": "WIA2plQuL4dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "7d54f4da-0f9d-4992-f87c-1fb35ababd42",
        "id": "0FuxRQdSMOep"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/exouser/Documents/RRR_MedVit/MedViT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/exouser/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "# Change directory to MedVit\n",
        "%cd ./MedViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "acebebd4-9243-4382-99dc-df2204b93ed3",
        "id": "_3uVFDABMh3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;32mColab_MedViT.ipynb\u001b[0m*  \u001b[01;32mLICENSE\u001b[0m*      \u001b[01;34mfracturemnist3d\u001b[0m/   \u001b[01;32mutils.py\u001b[0m*\n",
            "\u001b[01;34mCustomDataset\u001b[0m/       \u001b[01;32mMedViT.py\u001b[0m*    \u001b[01;34mimages\u001b[0m/\n",
            "\u001b[01;32mCustomDataset.md\u001b[0m*    \u001b[01;32mREADME.md\u001b[0m*    \u001b[01;32mrequirements.txt\u001b[0m*\n",
            "\u001b[01;32mInstructions.ipynb\u001b[0m*  \u001b[01;34m__pycache__\u001b[0m/  \u001b[01;34msynapsemnist3d\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "# Check Folder Content\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "61f9affd-4437-4087-9add-cda4ac4e8231",
        "collapsed": true,
        "id": "GIUv4u5ZMYrH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: timm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.0.9)\n",
            "Requirement already satisfied: medmnist in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (3.0.1)\n",
            "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: scikit-image in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.24.0)\n",
            "Requirement already satisfied: fvcore in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.1.5.post20221221)\n",
            "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (4.66.5)\n",
            "Requirement already satisfied: Pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (10.4.0)\n",
            "Requirement already satisfied: fire in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.6.0)\n",
            "Requirement already satisfied: torchattacks in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (3.5.1)\n",
            "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.17.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from timm->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from timm->-r requirements.txt (line 2)) (0.25.0)\n",
            "Requirement already satisfied: safetensors in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from timm->-r requirements.txt (line 2)) (0.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 5)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 5)) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-learn->-r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 7)) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 7)) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 7)) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 7)) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fvcore->-r requirements.txt (line 8)) (0.1.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fvcore->-r requirements.txt (line 8)) (2.4.0)\n",
            "Requirement already satisfied: tabulate in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fvcore->-r requirements.txt (line 8)) (0.9.0)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fvcore->-r requirements.txt (line 8)) (0.1.10)\n",
            "Requirement already satisfied: six in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fire->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: requests~=2.25.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchattacks->-r requirements.txt (line 12)) (2.25.1)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (1.13.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 13)) (12.6.68)\n",
            "Requirement already satisfied: portalocker in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from iopath>=0.1.7->fvcore->-r requirements.txt (line 8)) (2.10.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12)) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12)) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12)) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 13)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 13)) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install Dependencies\n",
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATMbGT0wROGU",
        "outputId": "4e3ce196-becc-436d-a040-5ec5f503ea87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ],
      "source": [
        "from MedViT import MedViT_small as tiny, MedViT_base as base\n",
        "model = base()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ie5GPMI2ROGU"
      },
      "outputs": [],
      "source": [
        "# Assuming you're using a GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI7_JeB0ROGU"
      },
      "outputs": [],
      "source": [
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=3, bias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APRpka4lROGU"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYvSik3jROGU",
        "outputId": "e1d79a0f-24a2-47dc-be62-eff4e80fd377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "multi-class\n"
          ]
        }
      ],
      "source": [
        "print(task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wct6zxAFROGU"
      },
      "outputs": [],
      "source": [
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzEbDvBZTA72"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX_ziTIbROGU",
        "outputId": "f6208ebd-8a23-44df-99a7-7b59686cc1be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 1027/1027 [08:51<00:00,  1.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 49.38%\n",
            "Epoch [2/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 1027/1027 [08:06<00:00,  2.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 53.20%\n",
            "Epoch [3/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 1027/1027 [07:53<00:00,  2.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 56.60%\n",
            "Epoch [4/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 1027/1027 [07:48<00:00,  2.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 59.42%\n",
            "Epoch [5/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 1027/1027 [09:20<00:00,  1.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 62.57%\n",
            "Epoch [6/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 1027/1027 [07:47<00:00,  2.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 65.24%\n",
            "Epoch [7/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 1027/1027 [07:33<00:00,  2.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 67.90%\n",
            "Epoch [8/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 1027/1027 [07:42<00:00,  2.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 70.24%\n",
            "Epoch [9/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 1027/1027 [08:14<00:00,  2.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 72.22%\n",
            "Epoch [10/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 1027/1027 [07:53<00:00,  2.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 74.22%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}]')\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    for inputs, targets, slice_numbers in tqdm(train_loader):  # This should now work correctly\n",
        "        inputs, targets = inputs.to(device), targets.to(device) # Move to GPU\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)  # Ensure targets are float\n",
        "            loss = criterion(outputs, targets)  # Binary cross-entropy loss\n",
        "        else:\n",
        "            targets = targets.squeeze().long()  # Ensure targets are long for class indices\n",
        "            loss = criterion(outputs, targets)  # Cross-entropy loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted class indices\n",
        "        train_total += targets.size(0)  # Total number of targets\n",
        "        train_correct += (predicted == targets).sum().item()  # Count correct predictions\n",
        "\n",
        "    # Calculate and print training accuracy for the epoch\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "    print(f'Training Accuracy: {train_accuracy:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy3ceXGJTA72"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'medvit_fracturemninst3_base_weights.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wZodZn1TA72"
      },
      "outputs": [],
      "source": [
        "# Save the entire model\n",
        "torch.save(model, 'medvit_fracturemninst3_base_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeeQsj3JROGS"
      },
      "source": [
        "# MedVit Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr5bpbunTA72",
        "outputId": "383397f2-50e8-4660-d390-f9fe1d87a0f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_5722/2898604408.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model = torch.load('medvit_fracturemninst3d_base_model.pth')\n"
          ]
        }
      ],
      "source": [
        "model = torch.load('medvit_fracturemninst3d_base_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKX8UVL9ROGX",
        "outputId": "0934017a-b60f-454f-a820-00e61751b52a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████| 240/240 [00:46<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 45.31%\n",
            "Precision: 0.42\n",
            "Recall: 0.40\n",
            "F1 Score: 0.40\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Validation loop\n",
        "model.eval()  # Set model to evaluation mode\n",
        "if task == \"multi-label, binary-class\":\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    total_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader):\n",
        "            inputs, labels, slice_numbers = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Convert 1-channel to 3-channel\n",
        "            # inputs = inputs.repeat(1, 3, 1, 1)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            outputs = torch.sigmoid(outputs)\n",
        "            print(\"outputs\", outputs) # Apply sigmoid for multi-label classification\n",
        "            predicted = (outputs > 0.5).int()  # Thresholding for binary classification\n",
        "\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            # Collect all labels and predictions for metric calculation\n",
        "            all_labels.extend(labels.cpu().numpy().flatten())\n",
        "            all_preds.extend(predicted.cpu().numpy().flatten())\n",
        "\n",
        "    accuracy = total_correct / (len(test_loader.dataset) * n_classes) * 100\n",
        "    print(f'Validation Accuracy: {accuracy:.2f}%')\n",
        "    # Calculate Precision, Recall, and F1 Score using sklearn\n",
        "    precision = precision_score(all_labels, all_preds, average='macro')\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "    print(f'Precision: {precision:.2f}')\n",
        "    print(f'Recall: {recall:.2f}')\n",
        "    print(f'F1 Score: {f1:.2f}')\n",
        "\n",
        "else:  # Multi-class classification\n",
        "    total_correct = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader):\n",
        "            inputs, labels, slice_numbers = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "             # Convert 1-channel to 3-channel\n",
        "            # inputs = inputs.repeat(1, 3, 1, 1)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)  # Get the predicted class\n",
        "\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "            # Collect all labels and predictions for metric calculation\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = total_correct / len(test_loader.dataset) * 100\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "    # Calculate Precision, Recall, and F1 Score using sklearn\n",
        "    precision = precision_score(all_labels, all_preds, average='macro')\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "\n",
        "    print(f'Precision: {precision:.2f}')\n",
        "    print(f'Recall: {recall:.2f}')\n",
        "    print(f'F1 Score: {f1:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx9_8gTPTA72"
      },
      "source": [
        "#Shannon entropy voting: GPU optimized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTdcP3cnTA72",
        "outputId": "1ad0bd5c-a25e-4d3c-d884-81b14ac8b28f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                   | 0/240 [00:00<?, ?it/s]/tmp/ipykernel_5722/603199177.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  batch_labels = torch.tensor(batch_labels).to(device)  # Move labels to GPU\n",
            "100%|█████████████████████████████████████████| 240/240 [00:46<00:00,  5.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3D Image-wise Accuracy: 37.50%\n",
            "Precision: 0.12\n",
            "Recall: 0.33\n",
            "F1-score: 0.18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/home/exouser/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate entropy for each slice's probability (on GPU)\n",
        "def calculate_entropy_gpu(probabilities):\n",
        "    # Entropy formula: H(X) = -p*log(p) - (1-p)*log(1-p)\n",
        "    entropy_values = -probabilities * torch.log(probabilities + 1e-10) - (1 - probabilities) * torch.log(1 - probabilities + 1e-10)\n",
        "    return entropy_values\n",
        "\n",
        "# Function to normalize entropies (on GPU)\n",
        "def normalize_entropies_gpu(entropies):\n",
        "    total_entropy = torch.sum(entropies)\n",
        "    if total_entropy == 0:\n",
        "        return torch.ones_like(entropies) / len(entropies)  # Handle zero entropy case\n",
        "    return entropies / total_entropy\n",
        "\n",
        "# Function to combine probabilities using the normalized entropy as weights (on GPU)\n",
        "def combine_probabilities_gpu(probabilities, weights):\n",
        "    return torch.sum(probabilities * weights)\n",
        "\n",
        "# Function to calculate 3D image-wise metrics for multiclass classification\n",
        "def calculate_3d_image_metrics_gpu(model, test_loader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    for batch_images, batch_labels, slice_numbers in tqdm(test_loader):\n",
        "        batch_images = batch_images.to(device)  # Move batch to GPU\n",
        "        batch_labels = torch.tensor(batch_labels).to(device)  # Move labels to GPU\n",
        "\n",
        "        # Step 1: Get prediction for each individual slice in the batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(batch_images)  # Model outputs for the 64 slices\n",
        "            softmax_outputs = F.softmax(outputs, dim=1)  # Apply softmax to get class probabilities\n",
        "            slice_probs, predicted_classes = torch.max(softmax_outputs, dim=1)  # Get max probability and predicted class for each slice\n",
        "\n",
        "        # Step 2: Calculate entropies for the 64 slices (on GPU)\n",
        "        entropies = calculate_entropy_gpu(slice_probs)\n",
        "\n",
        "        # Step 3: Normalize the entropies (on GPU)\n",
        "        weights = normalize_entropies_gpu(entropies)\n",
        "\n",
        "        # Step 4: Combine the probabilities using the entropy-based weights (on GPU)\n",
        "        combined_probs = combine_probabilities_gpu(slice_probs, weights)\n",
        "        combined_class = torch.argmax(combined_probs)  # Get the predicted class for the combined result\n",
        "\n",
        "        # Step 5: Get the true label (all slices in the batch have the same label)\n",
        "        true_label = batch_labels[0].item()  # All slices have the same label\n",
        "        predicted_labels.append(combined_class.item())  # Store predicted class\n",
        "        true_labels.append(true_label)  # Store true class\n",
        "\n",
        "    # Calculate metrics (on CPU for sklearn compatibility)\n",
        "    accuracy = sum(np.array(true_labels) == np.array(predicted_labels)) / len(true_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, average='macro')  # Use 'macro' for multiclass\n",
        "    recall = recall_score(true_labels, predicted_labels, average='macro')  # Use 'macro' for multiclass\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='macro')  # Use 'macro' for multiclass\n",
        "    #auc_roc = roc_auc_score(true_labels, predicted_labels, multi_class='ovr')  # Use 'ovr' for multiclass\n",
        "\n",
        "    return accuracy, precision, recall, f1 # auc_roc\n",
        "\n",
        "# Example usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)  # Move model to the appropriate device\n",
        "\n",
        "# Assuming test_loader is already defined\n",
        "accuracy, precision, recall, f1 = calculate_3d_image_metrics_gpu(model, test_loader, device)\n",
        "\n",
        "print(f\"3D Image-wise Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "# print(f\"A#UC-ROC: {auc_roc:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate entropy for each slice's probability (on GPU)\n",
        "def calculate_entropy_gpu(img):\n",
        "    #Histogram based entropy\n",
        "    pixel_values = img.flatten()\n",
        "    hist, _ = np.histogram(pixel_values, bins=256, range=(0, 255), density=True)\n",
        "    entropy_values = entropy(hist, base=2)\n",
        "    return entropy_values\n",
        "\n",
        "# Function to normalize entropies (on GPU)\n",
        "def normalize_entropies_gpu(entropies):\n",
        "    total_entropy = torch.sum(entropies)\n",
        "    if total_entropy == 0:\n",
        "        return torch.ones_like(entropies) / len(entropies)  # Handle zero entropy case\n",
        "    return entropies / total_entropy\n",
        "\n",
        "# Function to combine probabilities using the normalized entropy as weights (on GPU)\n",
        "def combine_probabilities_gpu(probabilities, weights):\n",
        "    return torch.sum(probabilities * weights)\n",
        "\n",
        "# Function to calculate 3D image-wise metrics\n",
        "def calculate_3d_image_metrics_gpu(model, test_loader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    for batch_images, batch_labels in test_loader:\n",
        "        batch_images = batch_images.to(device)  # Move batch to GPU\n",
        "        batch_labels = torch.tensor(batch_labels).to(device)  # Move labels to GPU\n",
        "\n",
        "        # Step 1: Get prediction for each individual slice in the batch\n",
        "        with torch.no_grad():\n",
        "            outputs = model(batch_images)  # Model outputs for the 64 slices\n",
        "            softmax_outputs = F.softmax(outputs, dim=1)  # Apply softmax to get probabilities\n",
        "            slice_probs = softmax_outputs[:, 1]  # Get probability for class 1 (binary classification)\n",
        "\n",
        "        # Step 2: Calculate entropies for the 64 slices (on GPU)\n",
        "        entropies = calculate_entropy_gpu(batch_images)\n",
        "\n",
        "        # Step 3: Normalize the entropies (on GPU)\n",
        "        weights = normalize_entropies_gpu(entropies)\n",
        "\n",
        "        # Step 4: Combine the probabilities using the entropy-based weights (on GPU)\n",
        "        combined_probability = combine_probabilities_gpu(slice_probs, weights)\n",
        "\n",
        "        # Step 5: Get the true label (all slices in the batch have the same label) and make a prediction\n",
        "        true_label = batch_labels[0]  # All slices have the same label\n",
        "        predicted_label = np.argmax(combined_probability)\n",
        "\n",
        "        # Store true and predicted labels for final metrics calculation (move to CPU for sklearn)\n",
        "        true_labels.append(true_label.item())\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # Calculate accuracy, precision, recall, and F1-score (on CPU for sklearn compatibility)\n",
        "    accuracy = sum(np.array(true_labels) == np.array(predicted_labels)) / len(true_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "    auc_roc = roc_auc_score(true_labels, predicted_labels)\n",
        "\n",
        "    return accuracy, precision, recall, f1, auc_roc\n",
        "\n",
        "# Example usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)  # Move model to the appropriate device\n",
        "\n",
        "# Assuming test_loader is already defined\n",
        "accuracy, precision, recall, f1, auc_roc = calculate_3d_image_metrics_gpu(model, test_loader, device)\n",
        "\n",
        "print(f\"3D Image-wise Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-score: {f1:.2f}\")\n",
        "print(f\"AUC-ROC: {auc_roc:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rBSSHBLiUmU",
        "outputId": "863352d3-dd3d-49cd-a096-450c1f9c0fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3D Image-wise Accuracy: 43.20%\n",
            "Precision: 0.39\n",
            "Recall: 0.41\n",
            "F1-score: 0.36\n",
            "AUC-ROC: 0.30\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}