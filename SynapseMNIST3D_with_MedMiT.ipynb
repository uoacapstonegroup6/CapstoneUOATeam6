{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uoacapstonegroup6/CapstoneUOATeam6/blob/main/SynapseMNIST3D_with_MedMiT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psI66xIdZ94u",
        "outputId": "a7ae3b33-29c6-4a2b-ec02-125a3123365b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (9.4.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.18.1+cu121)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.7.21)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->medmnist) (12.6.68)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Install if required\n",
        "!pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary packages\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "metadata": {
        "id": "0sw7dd-uaKR2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataflags\n",
        "\n",
        "data_flag = 'synapsemnist3d'\n",
        "download = True\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', download=download, size=64)\n",
        "test_dataset = DataClass(split='test', download=download, size=64)\n",
        "val_dataset = DataClass(split='val', download=download, size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDBSp-NRaL3j",
        "outputId": "60573b9e-f29b-4e12-fd38-5a19d9e8d983"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/synapsemnist3d_64.npz\n",
            "Using downloaded and verified file: /root/.medmnist/synapsemnist3d_64.npz\n",
            "Using downloaded and verified file: /root/.medmnist/synapsemnist3d_64.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function which converts a 3D image into 2D image in tensor format\n",
        "def image_3d_to_2d(dataset):\n",
        "\n",
        "  #Initializing empty lists to store 2D images\n",
        "  images = []\n",
        "  labels = []\n",
        "  index = []\n",
        "  print(\"Initial 3D images:\",len(dataset))\n",
        "\n",
        "  for i in range(len(dataset)):           #This loop runs for a few iterations as many as no. of 3D images\n",
        "    x, y = train_dataset[i]               #Extracting the image tensor (x) and label (y) from one 3D image\n",
        "    for j in range(len(x[0])):            #Getting into first batch of the selected 3D image. There will be only 1 batch and hence x[0] and len(x[0]) gives number of slices\n",
        "      img = x[0][j]                       #Array for every slice (j) is captured\n",
        "      arr = (img).astype(np.float32)      #Converting the normalized array into float\n",
        "      tensor = torch.tensor(arr)          #Converting array into tensor\n",
        "      images.append(tensor)               #Appending the image tensor into a list\n",
        "      labels.append(y[0])                 #Appending the label for the image into a list\n",
        "      index.append(i)                     #Appending the 3D image index into a list\n",
        "  print(\"Sliced 2D images:\",len(images))\n",
        "  return images, labels, index"
      ],
      "metadata": {
        "id": "hZtGnWmIaOl_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running the above function for train, test and validation.\n",
        "#Since the size=28, every 3D image has 28 slices\n",
        "\n",
        "train_2d = image_3d_to_2d(train_dataset)\n",
        "test_2d = image_3d_to_2d(test_dataset)\n",
        "val_2d = image_3d_to_2d(val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4v0Jhw9ahcd",
        "outputId": "bb6e64fd-3fa8-4cc3-e413-5c6393e94969"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial 3D images: 1230\n",
            "Sliced 2D images: 78720\n",
            "Initial 3D images: 352\n",
            "Sliced 2D images: 22528\n",
            "Initial 3D images: 177\n",
            "Sliced 2D images: 11328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Once sliced up, images are saved as .pth file\n",
        "\n",
        "images, labels, index = train_2d\n",
        "torch.save({'images': images, 'labels': labels, 'index':index}, 'synapse_train_2d.pth')\n",
        "images, labels, index = test_2d\n",
        "torch.save({'images': images, 'labels': labels, 'index':index}, 'synapse_test_2d.pth')\n",
        "images, labels, index = val_2d\n",
        "torch.save({'images': images, 'labels': labels, 'index':index}, 'synapse_val_2d.pth')"
      ],
      "metadata": {
        "id": "Qq-_q1f7ajIS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved dataset\n",
        "data_train = torch.load('synapse_train_2d.pth')\n",
        "data_test = torch.load('synapse_test_2d.pth')\n",
        "data_val = torch.load('synapse_val_2d.pth')\n",
        "\n",
        "# Convert the loaded images and labels to tensors\n",
        "tr_images = torch.stack(data_train['images'])  # Stack list of tensors into a single tensor\n",
        "tr_images = tr_images.unsqueeze(1)              #Forcefully adding n_channel=1\n",
        "tr_images_rgb = tr_images.repeat(1, 3, 1, 1)\n",
        "tr_labels = torch.tensor(data_train['labels'])  # Convert list of labels into a tensor\n",
        "# if tr_labels.ndimension() == 1:  # If it's (num_samples,)\n",
        "    # num_classes = 3  # Replace with actual number of classes\n",
        "    # tr_labels = torch.nn.functional.one_hot(tr_labels, num_classes=num_classes).float()\n",
        "tr_index = torch.tensor(data_train['index'])  # Convert list of indices into a tensor\n",
        "\n",
        "ts_images = torch.stack(data_test['images'])  # Stack list of tensors into a single tensor\n",
        "ts_images = ts_images.unsqueeze(1)              #Forcefully adding n_channel=1\n",
        "ts_images_rgb = ts_images.repeat(1, 3, 1, 1)\n",
        "ts_labels = torch.tensor(data_test['labels'])  # Convert list of labels into a tensor\n",
        "# if ts_labels.ndimension() == 1:  # If it's (num_samples,)\n",
        "#     num_classes = 3  # Replace with actual number of classes\n",
        "#     ts_labels = torch.nn.functional.one_hot(ts_labels, num_classes=num_classes).float()\n",
        "ts_index = torch.tensor(data_test['index'])  # Convert list of indices into a tensor\n",
        "\n",
        "val_images = torch.stack(data_val['images'])  # Stack list of tensors into a single tensor\n",
        "val_images = val_images.unsqueeze(1)              #Forcefully adding n_channel=1\n",
        "val_images_rgb = val_images.repeat(1, 3, 1, 1)\n",
        "val_labels = torch.tensor(data_val['labels'])  # Convert list of labels into a tensor\n",
        "val_index = torch.tensor(data_val['index'])  # Convert list of indices into a tensor\n",
        "\n",
        "# Create a TensorDataset from the loaded data\n",
        "dataset_train = data.TensorDataset(tr_images_rgb, tr_labels, tr_index)\n",
        "dataset_test = data.TensorDataset(ts_images_rgb, ts_labels, ts_index)\n",
        "dataset_val = data.TensorDataset(val_images_rgb, val_labels, val_index)\n",
        "\n",
        "# Create a DataLoader for batching and shuffling\n",
        "train_loader = data.DataLoader(dataset_train, batch_size=128, shuffle=True)\n",
        "test_loader = data.DataLoader(dataset_test, batch_size=128, shuffle=True)\n",
        "val_loader = data.DataLoader(dataset_val, batch_size=128, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ng01fonkak2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To see each batch of images\n",
        "# for batch in test_loader:\n",
        "#     batch_images, batch_labels, batch_index = batch\n",
        "#     print(batch_images.shape)  # Should be (batch_size, 1, 28, 28)\n",
        "#     print(batch_labels)"
      ],
      "metadata": {
        "id": "0Y78eahkqkit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "D9zDwpOheN_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Omid-Nejati/MedViT.git\n",
        "%cd /content/MedViT"
      ],
      "metadata": {
        "id": "koczSMhmeRku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "x9ucnZ8TWyh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from MedViT import MedViT_small as tiny, MedViT_base, MedViT_large\n",
        "\n",
        "model = tiny()"
      ],
      "metadata": {
        "id": "8gcycgIVeNqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you're using a GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "9MrreOh6kMRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=3, bias=True)"
      ],
      "metadata": {
        "id": "qIuDPwzR4tTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "XgoMb5GM-vas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "\n",
        "# task = 'multi-label, binary-class'\n",
        "model.eval()\n",
        "y_true = torch.tensor([]).cuda()\n",
        "y_score = torch.tensor([]).cuda()\n",
        "\n",
        "data_loader = test_loader\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets, index in data_loader:\n",
        "        inputs, targets, index = inputs.cuda(), targets.cuda(), index.cuda()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            outputs = outputs.softmax(dim=-1)\n",
        "            # print(1)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            outputs = outputs.softmax(dim=-1)\n",
        "            targets = targets.float().resize_(len(targets), 1)\n",
        "            # print(0)\n",
        "\n",
        "        y_true = torch.cat((y_true, targets), 0)\n",
        "        y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_score = y_score.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "OEFIqvJTeNcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actuals = y_true.squeeze().tolist()\n",
        "predictions = []\n",
        "y_score = y_score.tolist()\n",
        "for i in range(len(y_score)):\n",
        "  predictions.append(y_score[i].index(max(y_score[i])))"
      ],
      "metadata": {
        "id": "y5Y-0UaJBjJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = sum(a==p for a, p in zip(actuals, predictions))\n",
        "accuracy = (correct_predictions / len(actuals)) * 100"
      ],
      "metadata": {
        "id": "TO5UhasyCJZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "id": "qTQnt7FsXUuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(actuals, predictions, average='macro')\n",
        "recall = recall_score(actuals, predictions, average='macro')\n",
        "f1 = f1_score(actuals, predictions, average='macro')"
      ],
      "metadata": {
        "id": "COJ9i0dGW8Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "MbZ7y0erEDzl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}