{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psI66xIdZ94u",
        "outputId": "626caba0-c546-4462-dae5-919240052e64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.3.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.23.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (9.4.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.0+cu121)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Install if required\n",
        "!pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary packages\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "metadata": {
        "id": "0sw7dd-uaKR2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataflags\n",
        "\n",
        "data_flag = 'synapsemnist3d'\n",
        "download = True\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', download=download, size=64)\n",
        "test_dataset = DataClass(split='test', download=download, size=64)\n",
        "val_dataset = DataClass(split='val', download=download, size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDBSp-NRaL3j",
        "outputId": "0b2b5649-1d0c-471a-f047-a5c25f839a9d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/synapsemnist3d_64.npz\n",
            "Using downloaded and verified file: /root/.medmnist/synapsemnist3d_64.npz\n",
            "Using downloaded and verified file: /root/.medmnist/synapsemnist3d_64.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUgq0Dmr4Q8J",
        "outputId": "405e2ac3-1e6b-467c-ffd8-61ba852cdc38"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset SynapseMNIST3D of size 64 (synapsemnist3d_64)\n",
              "    Number of datapoints: 352\n",
              "    Root location: /root/.medmnist\n",
              "    Split: test\n",
              "    Task: binary-class\n",
              "    Number of channels: 1\n",
              "    Meaning of labels: {'0': 'inhibitory synapse', '1': 'excitatory synapse'}\n",
              "    Number of samples: {'train': 1230, 'val': 177, 'test': 352}\n",
              "    Description: The SynapseMNIST3D is a new 3D volume dataset to classify whether a synapse is excitatory or inhibitory. It uses a 3D image volume of an adult rat acquired by a multi-beam scanning electron microscope. The original data is of the size 100×100×100um^3 and the resolution 8×8×30nm^3, where a (30um)^3 sub-volume was used in the MitoEM dataset with dense 3D mitochondria instance segmentation labels. Three neuroscience experts segment a pyramidal neuron within the whole volume and proofread all the synapses on this neuron with excitatory/inhibitory labels. For each labeled synaptic location, we crop a 3D volume of 1024×1024×1024nm^3 and resize it into 28×28×28 voxels. Finally, the dataset is randomly split with a ratio of 7:1:2 into training, validation and test set.\n",
              "    License: CC BY 4.0"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function which converts a 3D image into 2D image in tensor format\n",
        "def image_3d_to_2d(dataset):\n",
        "\n",
        "  #Initializing empty lists to store 2D images\n",
        "  images = []\n",
        "  labels = []\n",
        "  index = []\n",
        "  print(\"Initial 3D images:\",len(dataset))\n",
        "\n",
        "  for i in range(len(dataset)):           #This loop runs for a few iterations as many as no. of 3D images\n",
        "    x, y = dataset[i]               #Extracting the image tensor (x) and label (y) from one 3D image\n",
        "    for j in range(len(x[0])):            #Getting into first batch of the selected 3D image. There will be only 1 batch and hence x[0] and len(x[0]) gives number of slices\n",
        "      img = x[0][j]                       #Array for every slice (j) is captured\n",
        "      arr = (img).astype(np.float32)      #Converting the normalized array into float\n",
        "      tensor = torch.tensor(arr)          #Converting array into tensor\n",
        "      images.append(tensor)               #Appending the image tensor into a list\n",
        "      labels.append(y[0])                 #Appending the label for the image into a list\n",
        "      index.append(i)                     #Appending the 3D image index into a list\n",
        "  print(\"Sliced 2D images:\",len(images))\n",
        "  return images, labels, index"
      ],
      "metadata": {
        "id": "hZtGnWmIaOl_"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running the above function for train, test and validation.\n",
        "#Since the size=28, every 3D image has 28 slices\n",
        "\n",
        "train_2d = image_3d_to_2d(train_dataset)\n",
        "test_2d = image_3d_to_2d(test_dataset)\n",
        "val_2d = image_3d_to_2d(val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4v0Jhw9ahcd",
        "outputId": "d6449fbb-3ced-49e7-e6db-24f339ce90d7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial 3D images: 1230\n",
            "Sliced 2D images: 78720\n",
            "Initial 3D images: 352\n",
            "Sliced 2D images: 22528\n",
            "Initial 3D images: 177\n",
            "Sliced 2D images: 11328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Once sliced up, images are saved as .pth file\n",
        "\n",
        "images, labels, index = train_2d\n",
        "torch.save({'images': images, 'labels': labels, 'index':index}, 'synapse_train_2d.pth')\n",
        "images, labels, index = test_2d\n",
        "torch.save({'images': images, 'labels': labels, 'index':index}, 'synapse_test_2d.pth')\n",
        "images, labels, index = val_2d\n",
        "torch.save({'images': images, 'labels': labels, 'index':index}, 'synapse_val_2d.pth')"
      ],
      "metadata": {
        "id": "Qq-_q1f7ajIS"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved dataset\n",
        "data_train = torch.load('synapse_train_2d.pth')\n",
        "data_test = torch.load('synapse_test_2d.pth')\n",
        "data_val = torch.load('synapse_val_2d.pth')\n",
        "\n",
        "# Convert the loaded images and labels to tensors\n",
        "tr_images = torch.stack(data_train['images'])  # Stack list of tensors into a single tensor\n",
        "tr_images = tr_images.unsqueeze(1)              #Forcefully adding n_channel=1\n",
        "tr_images_rgb = tr_images.repeat(1, 3, 1, 1)\n",
        "tr_labels = torch.tensor(data_train['labels'])  # Convert list of labels into a tensor\n",
        "# if tr_labels.ndimension() == 1:  # If it's (num_samples,)\n",
        "    # num_classes = 3  # Replace with actual number of classes\n",
        "    # tr_labels = torch.nn.functional.one_hot(tr_labels, num_classes=num_classes).float()\n",
        "tr_index = torch.tensor(data_train['index'])  # Convert list of indices into a tensor\n",
        "\n",
        "ts_images = torch.stack(data_test['images'])  # Stack list of tensors into a single tensor\n",
        "ts_images = ts_images.unsqueeze(1)              #Forcefully adding n_channel=1\n",
        "ts_images_rgb = ts_images.repeat(1, 3, 1, 1)\n",
        "ts_labels = torch.tensor(data_test['labels'])  # Convert list of labels into a tensor\n",
        "# if ts_labels.ndimension() == 1:  # If it's (num_samples,)\n",
        "#     num_classes = 3  # Replace with actual number of classes\n",
        "#     ts_labels = torch.nn.functional.one_hot(ts_labels, num_classes=num_classes).float()\n",
        "ts_index = torch.tensor(data_test['index'])  # Convert list of indices into a tensor\n",
        "\n",
        "val_images = torch.stack(data_val['images'])  # Stack list of tensors into a single tensor\n",
        "val_images = val_images.unsqueeze(1)              #Forcefully adding n_channel=1\n",
        "val_images_rgb = val_images.repeat(1, 3, 1, 1)\n",
        "val_labels = torch.tensor(data_val['labels'])  # Convert list of labels into a tensor\n",
        "val_index = torch.tensor(data_val['index'])  # Convert list of indices into a tensor\n",
        "\n",
        "# Create a TensorDataset from the loaded data\n",
        "dataset_train = data.TensorDataset(tr_images_rgb, tr_labels, tr_index)\n",
        "dataset_test = data.TensorDataset(ts_images_rgb, ts_labels, ts_index)\n",
        "dataset_val = data.TensorDataset(val_images_rgb, val_labels, val_index)\n",
        "\n",
        "# Create a DataLoader for batching and shuffling\n",
        "train_loader = data.DataLoader(dataset_train, batch_size=128, shuffle=True)\n",
        "test_loader = data.DataLoader(dataset_test, batch_size=128, shuffle=True)\n",
        "val_loader = data.DataLoader(dataset_val, batch_size=128, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng01fonkak2M",
        "outputId": "d4893259-5152-4aed-9b5f-2d45c3eb072c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-4afe41148add>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data_train = torch.load('synapse_train_2d.pth')\n",
            "<ipython-input-56-4afe41148add>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data_test = torch.load('synapse_test_2d.pth')\n",
            "<ipython-input-56-4afe41148add>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data_val = torch.load('synapse_val_2d.pth')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To see each batch of images\n",
        "# for batch in test_loader:\n",
        "#     batch_images, batch_labels, batch_index = batch\n",
        "#     print(batch_images.shape)  # Should be (batch_size, 1, 28, 28)\n",
        "#     print(batch_labels)"
      ],
      "metadata": {
        "id": "0Y78eahkqkit"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9zDwpOheN_u",
        "outputId": "17ebf2b0-2814-4ebf-aabb-e957a58de5e9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 18 16:16:02 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   69C    P0              32W /  72W |    723MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Omid-Nejati/MedViT.git\n",
        "%cd /content/MedViT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koczSMhmeRku",
        "outputId": "1ecc18b3-06f2-45b5-d865-0f19b7aa4fe0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MedViT'...\n",
            "remote: Enumerating objects: 176, done.\u001b[K\n",
            "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 176 (delta 87), reused 134 (delta 61), pack-reused 1 (from 1)\u001b[K\n",
            "Receiving objects: 100% (176/176), 820.48 KiB | 1.75 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n",
            "/content/MedViT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9ucnZ8TWyh0",
        "outputId": "309792a4-a7c6-49dd-9d78-61dc51d29145"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.0.9)\n",
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.23.2)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.1.5.post20221221)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (4.66.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (9.4.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.6.0)\n",
            "Requirement already satisfied: torchattacks in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.5.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.19.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 2)) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->-r requirements.txt (line 2)) (0.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 5)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 5)) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (3.3)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 8)) (0.1.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 8)) (2.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 8)) (0.9.0)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 8)) (0.1.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: requests~=2.25.1 in /usr/local/lib/python3.10/dist-packages (from torchattacks->-r requirements.txt (line 12)) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 13)) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 13)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 13)) (1.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 13)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 13)) (2024.6.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore->-r requirements.txt (line 8)) (2.10.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12)) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12)) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.25.1->torchattacks->-r requirements.txt (line 12)) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 13)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 13)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from MedViT import MedViT_small as tiny, MedViT_base, MedViT_large\n",
        "\n",
        "model = tiny()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gcycgIVeNqF",
        "outputId": "0a6eb928-9e93-4a68-e639-3ad01e1a17b1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you're using a GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "9MrreOh6kMRg"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=n_classes, bias=True)"
      ],
      "metadata": {
        "id": "qIuDPwzR4tTL"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQGJrhtKX_cw",
        "outputId": "86dc85ad-1bd5-4b7b-c70f-1c64afe87f0e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "XgoMb5GM-vas"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "\n",
        "# task = 'multi-label, binary-class'\n",
        "model.eval()\n",
        "y_true = torch.tensor([]).cuda()\n",
        "y_score = torch.tensor([]).cuda()\n",
        "\n",
        "data_loader = test_loader\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets, index in data_loader:\n",
        "        inputs, targets, index = inputs.cuda(), targets.cuda(), index.cuda()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            outputs = outputs.softmax(dim=-1)\n",
        "            # print(1)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            outputs = outputs.softmax(dim=-1)\n",
        "            targets = targets.float().resize_(len(targets), 1)\n",
        "            # print(0)\n",
        "\n",
        "        y_true = torch.cat((y_true, targets), 0)\n",
        "        y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "    y_true = y_true.cpu().numpy()\n",
        "    y_score = y_score.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "OEFIqvJTeNcV"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actuals = y_true.squeeze().tolist()\n",
        "predictions = []\n",
        "y_score = y_score.tolist()\n",
        "for i in range(len(y_score)):\n",
        "  predictions.append(y_score[i].index(max(y_score[i])))"
      ],
      "metadata": {
        "id": "y5Y-0UaJBjJT"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = sum(a==p for a, p in zip(actuals, predictions))\n",
        "accuracy = (correct_predictions / len(actuals))"
      ],
      "metadata": {
        "id": "TO5UhasyCJZe"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTQnt7FsXUuk",
        "outputId": "cbe5dee1-983c-4b85-b982-1f7b83d019fe"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7301136363636364"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(actuals, predictions, average='macro')\n",
        "recall = recall_score(actuals, predictions, average='macro')\n",
        "f1 = f1_score(actuals, predictions, average='macro')"
      ],
      "metadata": {
        "id": "COJ9i0dGW8Ow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969f227b-3a81-46e9-96b3-366d1294f1c2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy*100)\n",
        "print(\"Precision:\", precision*100)\n",
        "print(\"Recall:\", recall*100)\n",
        "print(\"F1 Score:\", f1*100)"
      ],
      "metadata": {
        "id": "MbZ7y0erEDzl",
        "outputId": "0ace3cff-05e9-47b2-a77e-3aadc405bb9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 73.01136363636364\n",
            "Precision: 36.50568181818182\n",
            "Recall: 50.0\n",
            "F1 Score: 42.200328407224966\n"
          ]
        }
      ]
    }
  ]
}